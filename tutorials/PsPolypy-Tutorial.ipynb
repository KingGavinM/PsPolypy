{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for PsPolypy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for this example\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Locate PsPolypy. Only necessary if PsPolypy is not installed as a package.\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "# Import PsPolypy\n",
    "import  PsPolypy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Polydat Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Polydat``` is object that stores and processes image fields containing polymer particles. The object can handle any number of full field images, provided they are the same nm/px resolution. A general outline of the ```Polydat```'s attributes are shown here:\n",
    "\n",
    "```project\n",
    "Polydat\n",
    "|- images (list[numpy.ndarray]):\n",
    "|     A list containing numpy arrays for each loaded full field image.\n",
    "|- resolution (float):\n",
    "|     The images' resolution in nm/px.\n",
    "|- metadata (Dict[str, any]):\n",
    "|     Dictionary containing key value pairs of arbitrary metadata. For example, the date of data acquisition could be stored as {'recorded_on':'12/25/24'}.\n",
    "|- particles (list[Particle]):\n",
    "|     List of Particle objects. Each Particle represents a detected polymer particle from the full field image. Set by the segment_particles method.\n",
    "|- num_particles (int):\n",
    "|     The total number of polymer particles detected in the full field images. Set by the segment_particles method.\n",
    "|- contour_lengths (list[float]):\n",
    "|     List containing the contour lengths for all branches detected in the particle list. Set by the interpolate_particles method.\n",
    "|- contour_sampling (numpy.ndarray):\n",
    "|     1-D array of interpolated contour sampling points. Ranges from 0 to the maximum detected contour length in a user defined step size. Set by the interpolate_particles method.\n",
    "|- mean_tantan_correlation (np.ndarray):\n",
    "|     1-D array of the tangent-tangent correlation averaged over all particle branches. Set by the calc_tantan_correlations method.\n",
    "|- pl (float):\n",
    "|     The persistence length of the polymer. Set by the calc_persistence_length method.\n",
    "|- plcov (float):\n",
    "|     The covariance of the persistence length fit. Set by the calc_persistence_length method.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an instance of Polydat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three means of creating an instance of the ```Polydat``` class. The first is to use the built-in class method ```from_images``` for creating an instance of ```Polydat``` from a list of image files. Additionally, you may wish to create an empty instance of the ```Polydat``` class and add images with the ```add_image``` method. The final option is to load the image to an array and pass it in to the class init. The three options are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Polydat class from a single image. Note, it must be a list of file paths, even if there is only one image.\n",
    "image_path = ['example_images/exampleCL0.png']\n",
    "polydat = PsPolypy.Polymer.Polydat.from_images(image_path, resolution = 2)\n",
    "# Check that the polydat object has been created correctly.\n",
    "print(f'The first polydat object contains {len(polydat.images)} image(s).')\n",
    "\n",
    "# Example of creating an instance of the Polydat class from a list of image file paths.\n",
    "image_paths = ['example_images/exampleCL0.png', 'example_images/exampleCL1.png']\n",
    "polydat = PsPolypy.Polymer.Polydat.from_images(image_paths, resolution = 2)\n",
    "# Check that the polydat object has been created correctly.\n",
    "print(f'The second polydat object contains {len(polydat.images)} image(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty instance of the Polydat class and add an image to it.\n",
    "polydat = PsPolypy.Polymer.Polydat()\n",
    "polydat.add_image('example_images/exampleCL0.png', resolution = 2)\n",
    "polydat.add_image('example_images/exampleCL1.png', resolution = 2)\n",
    "# Check that the polydat object has been created correctly.\n",
    "print(f'The polydat object contains {len(polydat.images)} image(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Polydat class from a list of numpy arrays.\n",
    "filepath = 'example_images/exampleCL0.png'\n",
    "with Image.open(filepath) as img:\n",
    "    grayscale = img.convert('L')\n",
    "    image_data = np.array(grayscale) / 255.0\n",
    "polydat = PsPolypy.Polymer.Polydat([image_data], resolution = 2)\n",
    "# Check that the polydat object has been created correctly.\n",
    "print(f'The polydat object contains {len(polydat.images)} image(s).')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing images with Polydat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a loaded instance of the ```Polydat``` class, the full field polymer image is ready to be processed.\n",
    "\n",
    "The first method for processing the image(s) is to (optionally) upscale them. The ```upscale``` method takes two inputs, ```magnification``` (int/float) and ```order``` (int). Each image has its shape multiplied by the ```magnification``` factor and interpolated by a 2D spline of ```order``` power. The upscaled image is set set back in the ```images``` attribute, i.e. this operation occurs in place. Furthermore, the ```resolution``` attribute is dynamically updated to reflect the new nm/px value. \n",
    "\n",
    "Note:\n",
    "\n",
    "The ```upscale``` method will raise an exception if the ```upscaled``` metadata is ```True```. This prevents upscaled images from being upscaled multiple times. After ```upscale``` is executing the ```metadata``` will be automatically updated with the key-value pair ```upscaled: True```. \n",
    "\n",
    "Though ```magnification```may be a floating point number, this may lead to warped images and unexpected behavior; it is preferrable to keep the magnification factor an integer. The interpolation ```order``` must be an integer from 0 to 5, indicating nearest-neighbor to bi-quintic interpolation. The default interpolation order is 3: bi-cubic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Polydat class from the test image.\n",
    "image_path = ['example_images/exampleCL0.png']\n",
    "polydat = PsPolypy.Polymer.Polydat.from_images(image_path, resolution = 2)\n",
    "# Extract the image from the polydat object.\n",
    "base_image = polydat.images[0]\n",
    "\n",
    "# Upscale the image by a factor of 2 using bi-cubic interpolation.\n",
    "polydat.upscale(magnification = 2, order = 3)\n",
    "# Extract the upscaled image from the polydat object.\n",
    "upscaled_image = polydat.images[0]\n",
    "\n",
    "# Plot the original and upscaled images for comparison.\n",
    "fig, ax = plt.subplots(1,2, figsize = (7,6))\n",
    "for axis in ax:\n",
    "    axis.axis('off')\n",
    "\n",
    "# Display the images.\n",
    "ax[0].imshow(base_image, cmap = 'gray')\n",
    "ax[0].set_title(f'Original {base_image.shape}')\n",
    "ax[1].imshow(upscaled_image, cmap = 'gray')\n",
    "ax[1].set_title(f'Upscaled {upscaled_image.shape}')\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whether or not the ```images``` are interpolated, we can proceed to detecting and segmenting the particles. This is done by executing the ```segment_particles``` method of the ```Polydat``` instance. This method takes two optional arguments: ```minimum_area``` (int) and ```padding``` (int). During the segmentation process, any particle whose area is less than ```minimum_area``` is discarded. When the particle images are cropped, the ```padding``` argument indicates how many padding pixels to include around the cropped region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segment the particles in the image.\n",
    "polydat.segment_particles()\n",
    "\n",
    "# Check to see how many particles were detected.\n",
    "print(f'The polydat object detected and segmented {polydat.num_particles} particles.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After segmentation, the ```particles``` attribute is set. It is a list containing ```Particle``` objects. A general outline of the relevant ```Particle``` attributes is shown here.\n",
    "\n",
    "```project\n",
    "Particle\n",
    "|- image (numpy.ndarray):\n",
    "|     The image of the particle.\n",
    "|- resolution (float):\n",
    "|     The images' resolution in nm/px. Inherited from Polydat class.\n",
    "|- bbox (Tuple[int,int,int,int]):\n",
    "|     The coordinates for the bounding box surrounding the particle.\n",
    "|- binary_mask (numpy.ndarray):\n",
    "|     The binary mask selecting the particle.\n",
    "|- classification (str):\n",
    "|     The particle classification. Linear, Branched, Branched-Loop, Looped, or Unknown\n",
    "|- particle_id (int):\n",
    "|     Unique identification number for the particle. Assigned by skimage.measure.regionprops.\n",
    "|- skeleton (skan.Skeleton):\n",
    "|     skan.Skeleton object of the particle.\n",
    "|- skelton_summary (pandas.DataFrame):\n",
    "|     The DataFrame created from skan.Summarize()\n",
    "|- contour_samplings (list[numpy.ndarray]):\n",
    "|     A list of the contour sampling for each path in the particle.\n",
    "|- contour_lengths (list[float]):\n",
    "|     A list of the contour length for each path in the particle.\n",
    "|- interp_skeleton_coordinates (list[numpy.ndarray]):\n",
    "|     The coordinates of each path of the particle's skeleton interpolated according to the contour sampling.\n",
    "|- interp_skeleton_derivatives (list[numpy.ndarray]):\n",
    "|     The derivatives of each interpolated path of the particle's skeleton.\n",
    "|- tantan_correlations (list[numpy.ndarray]):\n",
    "|     The tangent-tangent correlation of each interpolated path of the particle's skeleton.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the particles now segmented, let's visualize one using the ```plot_particle``` method. It takes the particle ```index```. Let's plot particle 0.\n",
    "\n",
    "**Note:** All plotting functions take the optional argument ```ax``` which chooses the ```matplotlib.pyplot.axis``` to draw to. If not explicitly specified, the current axis is selected with ```matplotlib.pyplot.gca```. For more information, see the Matplotlib documentation [here](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.gca.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which particle to view the image of.\n",
    "particle_index = 10\n",
    "\n",
    "# Create the figure and the axis for the particle image.\n",
    "particle_fig, ax = plt.subplots(figsize = (6,6))\n",
    "# Plot the image to the axis.\n",
    "ax = polydat.plot_particle(particle_index, cmap = 'gray')\n",
    "# Set the title of the plot.\n",
    "ax.set_title(f'Particle {particle_index} Image')\n",
    "# Turn the axis off\n",
    "ax.axis('off')\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skeletonize the particles with the default parameters.\n",
    "polydat.skeletonize_particles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the skeleton now set, we can view the particle skeletons with the ```plot_skeleton``` method. It functions similarly to the previous plotting method, taking in the ```index``` of the particle whose sekeleton to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which particle to view the skeleton of.\n",
    "particle_index = 10\n",
    "\n",
    "# Create the figure and the axis for the skeleton image.\n",
    "skeleton_fig1, ax = plt.subplots(figsize = (6,6))\n",
    "# Plot the skeleton image to the axis.\n",
    "ax = polydat.plot_skeleton(particle_index, cmap = 'gray')\n",
    "# Set the title of the plot.\n",
    "ax.set_title(f'Particle {particle_index} Skeleton')\n",
    "# Turn the axis off\n",
    "ax.axis('off')\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The particle skeletons can now be interpolated with a 2D interpolating spline. The ```interpolate_skeletons``` method interpolates each particle skeleton along the contur in a user defined ```step_size``` (float). ```step_size``` should be set below 1 to sample the contour above the current pixel resolution. The optional arguments for the interpolation order ```k``` (int) and smoothing ```s``` (float) are passed to ```scipy.interpolate.splprep```. For more information see the scipy documentation [here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.interpolate.splprep.html#scipy.interpolate.splprep).\n",
    "\n",
    "This sets the ```contour_lengths```, ```contour_samplings```, ```interp_skeleton_coordinates```, and ```interp_skeleton_derivatives``` attributes. Furthermore, the ```plot_interpolated_skeleton``` method will now display the interpolated skeleton contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the skeletons of the particles.\n",
    "polydat.interpolate_skeletons(step_size = 0.5, k = 3, s = 0.5)\n",
    "\n",
    "# Select which particle to view the interpolated skeleton of.\n",
    "particle_index = 10\n",
    "\n",
    "# Create the figure and the axis for the skeleton image.\n",
    "skeleton_fig2, ax = plt.subplots(figsize = (6,6))\n",
    "# Plot the skeleton image to the axis.\n",
    "ax = polydat.plot_skeleton(particle_index, cmap = 'gray')\n",
    "# Plot the interpolated skeleton to the axis.\n",
    "ax = polydat.plot_interpolated_skeleton(particle_index, lw = 6, color = 'red')\n",
    "# Set the title of the plot.\n",
    "ax.set_title(f'Particle {particle_index} Interpolated Skeleton')\n",
    "# Turn the axis off\n",
    "ax.axis('off')\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ```contour_lengths``` attribute set, we can now plot a distribution of the contour lengths of all particle paths. This is done by executing the ```plot_contour_distribution``` method. This plotting takes in ```Dict```s of keyword arguments passed to matplotlib. Because we're plotting the full contour length distribution, the kwargs for controling the plot are ```inc_dist_kwargs``` and ```inc_fill_kwargs``` for the distribtuion and fill respectively. See the docstring for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure and the axis for the contour distribution.\n",
    "contour_distribution_fig1, ax = plt.subplots(figsize = (6,6))\n",
    "\n",
    "# Plot the contour length distribution.\n",
    "ax = polydat.plot_contour_distribution(n_points = 1000,\n",
    "                                       inc_dist_kwargs = {'color': 'Blue', 'lw': 2,},\n",
    "                                       inc_fill_kwargs = {'color': 'LightBlue', 'alpha': 0.5})\n",
    "# Set the title of the plot.\n",
    "ax.set_title('Contour Length Distribution')\n",
    "# Set the axis labels.\n",
    "ax.set_xlabel(f'Contour Length (x{polydat.resolution} nm)')\n",
    "ax.set_ylabel('Probability Density')\n",
    "# Set the axis limits.\n",
    "ax.set_ylim([0,0.085])\n",
    "ax.set_xlim([0,75])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying The Particles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the```skeleton```s are set, the particles can be classified by executing the ```classify_particles``` method. This sets the ```classification``` attribute. Each particle is classified by the following criteria:\n",
    "- If the particle contains a single branch path with two different endpoints, the particle is classified as ```Linear```.\n",
    "- If the particle contains a single branch path with the same end points, the particle is classified as ```Looped```.\n",
    "- If the particle contains multiple branch paths that intersect at a branch point but no cycles (A point can be revisited when traveling along a set of branch paths), the particle is classified as ```Branched```.\n",
    "- If the particle contains multiple branch paths that intersect at a branch point and includes cycles, the particle is classified as ```Brached-Looped```.\n",
    "- If none of the above criteria are met, the particle is classified as ```Unknown```. This should not occur, but is included for safety.\n",
    "\n",
    "Once the skeletons are classified, you can return a subset of the ```particles``` list attribute using the ```get_filtered_particles``` method passing in the ```filter_str``` (str) matching the particles type you want. Additionally, the ```plot_particle``` and ```plot_skeleton``` methods will automatically display the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the Particles\n",
    "polydat.classify_particles()\n",
    "\n",
    "# Get the number of particles in the Linear classification.\n",
    "linear_particles = polydat.get_filtered_particles('Linear')\n",
    "print(f'The number of linear particles is {len(linear_particles)}.')\n",
    "\n",
    "# Select the first particle in the Linear classification.\n",
    "particle = linear_particles[0]\n",
    "\n",
    "# Create the figure and the axis for the particle image.\n",
    "linear_skeleton_fig, ax = plt.subplots(figsize = (6,6))\n",
    "# Plot the first particle's skeleton.\n",
    "ax = particle.plot_skeleton(cmap = 'gray')\n",
    "# Plot the first particle's interpolated skeleton.\n",
    "ax = particle.plot_interpolated_skeleton(lw = 6, color = 'red')\n",
    "# Set the title of the plot.\n",
    "ax.set_title(f'Particle {particle.id} Interpolated Skeleton - {particle.classification}')\n",
    "# Turn the axis off\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the Persistence Length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the interpolated skeleton is set, the mean tangent-tangent correlation is calculated by executing the ```calc_tantan_correlations``` method. The tangent-tangent correlation is calculated for each branch in all particles and stored in the particles' ```tantan_correlations``` attribute. The user can also calculate the tangent-tangent correlations for a set of specific particle classifications by passing in the ```included_classifications``` argument. The correlations are abs-averaged for each contour length in ```contour_samplings```, the aboslute value is taken, and the output is set to the ```mean_tantan_correlation``` attribute. \n",
    "\n",
    "Once the ```mean_tantan_correlation``` is set, we can plot it with the ```plot_mean_tantan_correlation``` method. It takes a single optional argument ```error_bars``` (bool) to turn error bars on and off. Furthermore, the plotting function includes keyword argument dictionaries ```inc_kwargs``` and ```exc_kwargs``` for altering the color of the correlation, its errorbars, etc. See the source code for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the tangent-tangent correlation functions for all the particles.\n",
    "polydat.calc_tantan_correlations(included_classifications = ['Linear', 'Branched', 'Branched-Looped', 'Looped'])\n",
    "\n",
    "tantan_correlation_fig1, ax = plt.subplots(figsize = (6,6))\n",
    "# Plot the mean tangent-tangent correlation function.\n",
    "ax = polydat.plot_mean_tantan_correlation(error_bars = True,\n",
    "                                          inc_kwargs = {'color': 'Blue', 'fmt': '.', 'ecolor': 'LightBlue'},\n",
    "                                          exc_kwargs = {'color': 'Gray', 'fmt': '.', 'ecolor': 'LightGray'})\n",
    "# Set the title of the plot.\n",
    "ax.set_title('Mean Tangent-Tangent Correlation')\n",
    "# Set the axis labels.\n",
    "ax.set_xlabel(f'Distance (x{polydat.resolution} nm)')\n",
    "ax.set_ylabel('abs <Correlation>')\n",
    "# Set the axis limits.\n",
    "ax.set_xlim(0,60)\n",
    "ax.set_ylim(0,1.05)\n",
    "# Turn the grid on.\n",
    "ax.grid()\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, calculating the persistence length can be done with the ```calc_tantan_lp``` method. It accepts two optional arguments, ```min_fitting_length``` (float) and ```max_fitting_length``` (float). Because the correlation contribution from low contour lengths can bias the fit, and the sampling of very long contour lengths is very low, the decaying exponential is only fit between these two values. Executing ```calc_tantan_lp``` sets the ```tantan_fit_result``` parmeter with a ```lmfit.model.ModelResult```. For more information about the result see the documentation [here](https://lmfit.github.io/lmfit-py/model.html#lmfit.model.ModelResult).\n",
    "\n",
    "Once the persistence length is calculated, we can see a summary of the polydat object with ```print_summary``` method. The ```plot_mean_tantan_correlation_fit``` method plots the fitted exponential. If the ```show_init``` argument is ```True```, the initial guess at the fit is shown along side the best fit. The ```fit_kwargs``` and ```init_kwargs``` can be set to adjust the parameters of the fit and initial guess plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the persistence length of the particles.\n",
    "polydat.calc_tantan_lp(min_fitting_length = 7, max_fitting_length = 40)\n",
    "\n",
    "# Print a summary of the polydat object.\n",
    "polydat.print_summary()\n",
    "\n",
    "tantan_correlation_fig2, ax = plt.subplots(figsize = (6,6))\n",
    "# Plot the mean tangent-tangent correlation function.\n",
    "ax = polydat.plot_mean_tantan_correlation(error_bars = True,\n",
    "                                          inc_kwargs = {'color': 'Blue', 'fmt': '.', 'ecolor': 'LightBlue', 'label': 'Fitted Data'},\n",
    "                                          exc_kwargs = {'color': 'Gray', 'fmt': '.', 'ecolor': 'LightGray', 'label': 'Excluded Data'})\n",
    "# Plot the fitted decaying exponential.\n",
    "ax = polydat.plot_mean_tantan_correlation_fit(show_init = True,\n",
    "                                              fit_kwargs = {'color': 'Red', 'lw': 1.5, 'label': 'Best Fit'},\n",
    "                                              init_kwargs = {'color': 'Red', 'lw': 0.75, 'linestyle': '--', 'label': 'Initial Guess'})\n",
    "# Set the title of the plot.\n",
    "ax.set_title('Mean Tangent-Tangent Correlation')\n",
    "# Set the axis labels.\n",
    "ax.set_xlabel(f'Distance (x{polydat.resolution} nm)')\n",
    "ax.set_ylabel('abs <Correlation>')\n",
    "ax.legend()\n",
    "# Set the axis limits.\n",
    "ax.set_xlim(0,60)\n",
    "ax.set_ylim(0,1.05)\n",
    "# Turn the grid on.\n",
    "ax.grid()\n",
    "# Display the plot.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polydat.tantan_fit_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the end-to-end workflow for processing a set of polymer images for all classification types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create a list of the files to be analyzed.\n",
    "filepaths = ['example_images/exampleCL0.png', 'example_images/exampleCL1.png']\n",
    "# Create an instance of the Polydat class from the list of file paths.\n",
    "polydat = PsPolypy.Polymer.Polydat.from_images(filepaths = filepaths, resolution = 2)\n",
    "# Upscale the image by a factor of 2 using bi-cubic interpolation.\n",
    "polydat.upscale(magnification = 2, order = 3)\n",
    "# Segment the particles in the image.\n",
    "polydat.segment_particles()\n",
    "# Skeletonize the particles.\n",
    "polydat.skeletonize_particles()\n",
    "# Classify the particles.\n",
    "polydat.classify_particles()\n",
    "# Interpolate the skeletons of the particles.\n",
    "polydat.interpolate_skeletons(step_size = 0.5, k = 3, s = .5)\n",
    "# Calculate the tangent-tangent correlation for the particles.\n",
    "polydat.calc_tantan_correlations()\n",
    "# Calculate the persistence length.\n",
    "polydat.calc_tantan_lp(min_fitting_length = 7, max_fitting_length = 40)\n",
    "# Print a summary of the polydat object.\n",
    "polydat.print_summary()\n",
    "\n",
    "# Create a figure containing the complete workflow plots.\n",
    "complete_workflow_fig, ax = plt.subplots(2,1, figsize = (7,11))\n",
    "\n",
    "# Plot contour length distribution\n",
    "ax[0] = polydat.plot_contour_distribution(n_points = 1000, ax = ax[0],\n",
    "                                          inc_dist_kwargs = {'color': 'Blue', 'lw': 2, 'label': 'Included Distribution'},\n",
    "                                          inc_fill_kwargs = {'color': 'LightBlue', 'alpha': 0.5},\n",
    "                                          exc_dist_kwargs = {'color': 'Gray', 'lw': 2, 'alpha': 0.5, 'label': 'Excluded Distribution'},\n",
    "                                          exc_fill_kwargs = {'color': 'LightGray', 'alpha': 0.5},\n",
    "                                          vline_kwargs = {'color': 'Blue', 'lw': 1.5, 'linestyle': '--'})\n",
    "ax[0].set_xlim([0,60])\n",
    "ax[0].set_ylim([0,0.065])\n",
    "ax[0].grid(lw=0.3)\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot tangent-tangent correlation with the fit.\n",
    "ax[1] = polydat.plot_mean_tantan_correlation(error_bars = True, ax = ax[1],\n",
    "                                             inc_kwargs = {'color': 'Blue', 'fmt': '.', 'ecolor': 'LightBlue', 'label': 'Fitted Data'},\n",
    "                                             exc_kwargs = {'color': 'Gray', 'fmt': '.', 'ecolor': 'LightGray', 'label': 'Excluded Data'})\n",
    "ax[1] = polydat.plot_mean_tantan_correlation_fit(show_init = True, ax = ax[1],\n",
    "                                                 fit_kwargs = {'color': 'Red', 'lw': 1.5, 'label': 'Best Fit'},\n",
    "                                                 init_kwargs = {'color': 'Red', 'lw': 0.75, 'linestyle': '--', 'label': 'Initial Guess'})\n",
    "ax[1].set_xlim([0,60])\n",
    "ax[1].set_ylim(0,1.05)\n",
    "ax[1].grid(lw=0.3)\n",
    "ax[1].legend()\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()\n",
    "# Show the fitting results.\n",
    "polydat.tantan_fit_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the end-to-end workflow for processing a set of polymer images only considering the linear classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the files to be analyzed.\n",
    "filepaths = ['example_images/exampleCL0.png', 'example_images/exampleCL1.png']\n",
    "# Create an instance of the Polydat class from the list of file paths.\n",
    "polydat = PsPolypy.Polymer.Polydat.from_images(filepaths = filepaths, resolution = 2)\n",
    "# Upscale the image by a factor of 2 using bi-cubic interpolation.\n",
    "polydat.upscale(magnification = 2, order = 3)\n",
    "# Segment the particles in the image.\n",
    "polydat.segment_particles()\n",
    "# Skeletonize the particles.\n",
    "polydat.skeletonize_particles()\n",
    "# Classify the particles.\n",
    "polydat.classify_particles()\n",
    "# Interpolate the skeletons of the particles.\n",
    "polydat.interpolate_skeletons(step_size = 0.5, k = 3, s = .5)\n",
    "# Calculate the tangent-tangent correlation for the particles. Include only the Linear classification.\n",
    "polydat.calc_tantan_correlations(included_classifications = ['Linear'])\n",
    "# Calculate the persistence length.\n",
    "polydat.calc_tantan_lp(min_fitting_length = 7, max_fitting_length = 40)\n",
    "# Print a summary of the polydat object.\n",
    "polydat.print_summary()\n",
    "\n",
    "# Create a figure containing the complete workflow plots.\n",
    "complete_workflow_fig, ax = plt.subplots(2,1, figsize = (7,11))\n",
    "\n",
    "# Plot contour length distribution\n",
    "ax[0] = polydat.plot_contour_distribution(n_points = 1000, ax = ax[0],\n",
    "                                          inc_dist_kwargs = {'color': 'Blue', 'lw': 2, 'label': 'Included Distribution'},\n",
    "                                          inc_fill_kwargs = {'color': 'LightBlue', 'alpha': 0.5},\n",
    "                                          exc_dist_kwargs = {'color': 'Gray', 'lw': 2, 'alpha': 0.5, 'label': 'Excluded Distribution'},\n",
    "                                          exc_fill_kwargs = {'color': 'LightGray', 'alpha': 0.5},\n",
    "                                          vline_kwargs = {'color': 'Blue', 'lw': 1.5, 'linestyle': '--'})\n",
    "ax[0].set_xlim([0,60])\n",
    "ax[0].set_ylim([0,0.065])\n",
    "ax[0].grid(lw=0.3)\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot tangent-tangent correlation with the fit.\n",
    "ax[1] = polydat.plot_mean_tantan_correlation(error_bars = True, ax = ax[1],\n",
    "                                             inc_kwargs = {'color': 'Blue', 'fmt': '.', 'ecolor': 'LightBlue', 'label': 'Fitted Data'},\n",
    "                                             exc_kwargs = {'color': 'Gray', 'fmt': '.', 'ecolor': 'LightGray', 'label': 'Excluded Data'})\n",
    "ax[1] = polydat.plot_mean_tantan_correlation_fit(show_init = True, ax = ax[1],\n",
    "                                                 fit_kwargs = {'color': 'Red', 'lw': 1.5, 'label': 'Best Fit'},\n",
    "                                                 init_kwargs = {'color': 'Red', 'lw': 0.75, 'linestyle': '--', 'label': 'Initial Guess'})\n",
    "ax[1].set_xlim([0,60])\n",
    "ax[1].set_ylim(0,1.05)\n",
    "ax[1].grid(lw=0.3)\n",
    "ax[1].legend()\n",
    "\n",
    "# Display the plot.\n",
    "plt.show()\n",
    "# Show the fitting results\n",
    "polydat.tantan_fit_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Versions of used packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark --python --packages numpy,scipy,networkx,skan,matplotlib,PIL,skimage,lmfit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PsPolypy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
